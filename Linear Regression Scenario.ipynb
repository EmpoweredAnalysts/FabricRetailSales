{"cells":[{"cell_type":"markdown","source":["# **Scenario: Retail Sales Forecasting with Microsoft Fabric**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"aae46869-0521-4b67-843a-c9d39f8e36dc"},{"cell_type":"markdown","source":["### **Business Context**\n","\n","\n","#### A nationwide retailer wants to predict monthly store **sales revenue** in order to optimize advertising budgets, promotional activity, and staffing. By understanding which operational and market factors drive sales, they can allocate resources more effectively and increase ROI.\n","\n","\n","________________________________________\n","\n","##### **Dataset Summary**\n","###### Scope: 40 stores × 24 months = 960 rows (store-month grain)<br><br>\n","##### Although there are different columns available, we're going to focus on the ones identified below.<br><br>\n","\n","##### **Target (Dependent Variable):** monthly_sales → total store revenue for the month.<br><br>\n","\n","##### **Independent Variables (features):**\n","###### 1. ad_spend → monthly advertising budget.\n","###### 2. foot_traffic → estimated store visits.\n","###### 3. avg_price → average product price.\n","###### 4. staff_count → number of staff scheduled.\n","###### 5. store_size_sqft → size of the store.\n","###### 6. promo_days → number of promotional days in the month.\n","###### 7. local_income_index → index of local income levels (100 = national average).\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6969f35f-08bc-4b66-9c20-5a19539e9990"},{"cell_type":"markdown","source":["# **Read data from Github repository**\n","\n","#### https://github.com/EmpoweredAnalysts/FabricRetailSales"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b52974bd-0436-429f-86ee-9a3889251848"},{"cell_type":"code","source":["#read the csv file from the github repo containing the Retail dataset\n","import pandas as pd \n","\n","retail_github_repo = pd.read_csv(\"https://github.com/EmpoweredAnalysts/FabricRetailSales/raw/refs/heads/main/retail_sales_demo_data.csv\")\n","\n","retail_github_repo.head(10)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d19ffd0e-c6fc-4500-9443-7bd4ed43cc57"},{"cell_type":"code","source":["# Load data to tables \n","# we need to use spark to write it to the tables section of the Lakehouse which is why we are converting it to a spark dataframe)\n","\n","# Convert pandas DataFrames to PySpark DataFrames\n","retail_github_repo_spark = spark.createDataFrame(retail_github_repo)\n","\n","# Write DataFrames to Delta table\n","retail_github_repo_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"monthly_retail\")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a0c9f0e-c3e4-44df-8c7d-6ffb5ec70ffe"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","### **Activity:**\n","#### Run the code cells above to source the data and create the monthly_retail table in the lakehouse"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2db06a7d-a84b-4377-a4eb-63c1aa8ab88d"},{"cell_type":"markdown","source":["## Select specific fields for analysis and convert to pandas dataframe from a pyspark dataframe"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6cdb2184-4f97-445a-96b3-3548647078f9"},{"cell_type":"code","source":["Retail_Sales = (\n","    spark.table(\"monthly_retail\")\n","         .select(\n","                \"monthly_sales\",\n","                \"ad_spend\",\n","                \"foot_traffic\",\n","                \"avg_price\",\n","                \"staff_count\",\n","                \"store_size_sqft\",\n","                \"promo_days\",\n","                \"local_income_index\"\n","                )\n","                )\n","\n","\n","Retail_Sales_pd = Retail_Sales.toPandas()\n","\n","Retail_Sales_pd.head()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"f237a6d9-f45d-46b6-9fae-1d0c12557e36"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","### **Activity:**\n","#### Run the code cell above to select specific fields from the monthly_retail table and available as a pandas dataframe"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8c1088aa-beb6-4433-948c-b28659db9e5d"},{"cell_type":"markdown","source":["# **Exploratory Data Analysis**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b5b7f096-270a-4633-bd75-2012508d57da"},{"cell_type":"markdown","source":["### The dataset contains some missing values in the column \"ad_spend\" and an extremely high value in the column \"foot_traffic\".\n","\n","#### We'll identify these values using Data Wrangler and remove them from the analysis before moving onto explore our data using a correlation matrix and some scatterplots"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"843291f1-c927-4950-b289-3b0d396f87c5"},{"cell_type":"markdown","source":["### **1.  Explore data in Data Wrangler**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8022293a-ca83-4878-ba3a-2a31b5746139"},{"cell_type":"markdown","source":["\n","#### To use Data Wrangler ensure you have run the previous cells as there need to be active dataframes available for it to work.\n","\n","#### Go to the ribbon - **Data Wrangler**, click on the drop down and choose the **dataframe** you want to explore.\n","\n","#### We'll use the pandas dataframe **Retail_Sales_pd**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"576c3a9d-d32d-48b8-9d35-415de7e47ce7"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Open Data Wrangler, selecting the pandas dataframe **Retail_Sales_pd**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8a027f75-a56c-4898-b736-0942511ff784"},{"cell_type":"markdown","source":["### **2. Clean data in Data Wrangler**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3dae8274-35db-489a-ac76-d8775161fcce"},{"cell_type":"code","source":["# Code generated by Data Wrangler for pandas DataFrame\n","\n","def clean_data(Retail_Sales_pd):\n","    # Filter rows based on column: 'ad_spend'\n","    Retail_Sales_pd = Retail_Sales_pd[Retail_Sales_pd['ad_spend'].notna()]\n","    # Filter rows based on column: 'foot_traffic'\n","    Retail_Sales_pd = Retail_Sales_pd[Retail_Sales_pd['foot_traffic'] < 500000]\n","    return Retail_Sales_pd\n","\n","Retail_Sales_pd_clean = clean_data(Retail_Sales_pd.copy())\n","Retail_Sales_pd_clean.head()"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"7e556e7e-d2a6-4479-9439-22723b8248b3"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Add code from Data Wrangler in a cell below that cleans the data and run the code:\n","##### 1. Filters out the missing values from ad_spend \n","##### 2. Filters out the outlier (>500k) from foot_traffic"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8f7d839f-763f-4618-8758-aa2ddc24a769"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ffa41c11-b4ef-40e8-90ea-5c46b2c9e473"},{"cell_type":"markdown","source":["### **3. Correlation Matrix**"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"2eec5b3b-0bb2-4a5d-91f6-ed03a8337636"},{"cell_type":"code","source":["#import packages\n","import matplotlib.pyplot as plt\n","import seaborn as sns  # for the heatmap\n","\n","# Compute correlation matrix\n","corr_matrix = Retail_Sales_pd_clean.corr()\n","\n","corr_matrix"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d437a4a7-cb42-428e-ad36-55654de36752"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the code to create the correlation matrix\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a94e44cf-5cb5-4abd-bfa4-5db429359dff"},{"cell_type":"markdown","source":["### **4. Scatterplots**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c7c17aa7-316b-4009-b2a2-b4cac5749387"},{"cell_type":"code","source":["import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","# Set up subplots\n","fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n","\n","# Scatterplots\n","sns.scatterplot(data=Retail_Sales_pd_clean, x=\"ad_spend\", y=\"monthly_sales\", alpha=0.6, ax=axes[0])\n","axes[0].set_title(\"Monthly Sales vs Ad Spend\")\n","\n","sns.scatterplot(data=Retail_Sales_pd_clean, x=\"foot_traffic\", y=\"monthly_sales\", alpha=0.6, ax=axes[1])\n","axes[1].set_title(\"Monthly Sales vs Foot Traffic\")\n","\n","sns.scatterplot(data=Retail_Sales_pd_clean, x=\"avg_price\", y=\"monthly_sales\", alpha=0.6, ax=axes[2])\n","axes[2].set_title(\"Monthly Sales vs Avg Price\")\n","\n","plt.tight_layout()\n","plt.show()\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"66c5f24f-7d66-41b8-ac69-06e8e5370a7a"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the code to create the scatterplots\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"901a6daa-a520-482b-8b81-d35d7907328c"},{"cell_type":"markdown","source":["### **Hypothesis**\n","\n","#### We will use the variables **Ad Spend**, **Foot Traffic** and **Avg Price** to take into our model\n","\n","##### H1 — **Advertising Spend**: Increasing advertising spend is positively associated with higher monthly sales.\n","##### H2 — **Foot Traffic**: Higher foot traffic leads to higher monthly sales.\n","##### H3 — **Average Price**: An increase in average price has a measurable relationship with monthly sales"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"842f7cf0-b961-43f1-a630-6b615849be0e"},{"cell_type":"markdown","source":["# **Linear Regression**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b1958fe-ec0f-40a6-ac09-9f975509222d"},{"cell_type":"markdown","source":["## **Graphical User Interface (GUI) & Code Based** <br><br>\n","\n","##### Our aim in this section is to:\n","##### 1.\tCreate an Experiment and get set up with MLflow\n","##### 2.\tCreate our linear regression model\n","##### 3.\tImprove the regression model by adjusting the variables and we’ll the view the runs that are created within the experiment we’ve set up. This will allow us to compare those different runs.\n","##### 4.    Save the run as an ML model\n","\n","##### _This section is a mixture of using the visual interface in Fabric as well as code. We’ll then go onto repeat this process using a code only approach_"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"70a59b33-d191-4ead-801c-2729a41672a5"},{"cell_type":"markdown","source":["### 1. Create an Experiment and MLflow set up"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ff398a1b-828d-40a4-8c1b-f1172b5a863b"},{"cell_type":"markdown","source":["#### An experiment is a container that allows us to log information about our machine learning code like parameters, code versions and output files. You can visualize, search for and compare different runs.\n","\n","#### You can find more information at https://learn.microsoft.com/en-us/fabric/data-science/machine-learning-experiment\n","\n","#### To create an experiment using the visual interface in Fabric – go to the workspace you are working in\n","#### &nbsp;&nbsp;&nbsp; ●  Click on New item (top left)\n","#### &nbsp;&nbsp;&nbsp; ●  Under **Analyze and train data** select **Experiment**\n","#### &nbsp;&nbsp;&nbsp; ● Name the Experiment **Experiment1**: <u>MAKE SURE THERE ARE NO SPACES!!!</u>\n","#### &nbsp;&nbsp;&nbsp; ● Observe the item has been added to the workspace. Go to the workspace, and observe that the experiment is now an item in the workspace. It’s ready for runs to be allocated to it\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"512e5731-2bea-42b7-9b54-0719fa26f29b"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Create an experiment using the visual interface in Microsoft Fabric - call it **Experiment1**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6c0a3352-abd5-4588-aa95-2001d292a933"},{"cell_type":"markdown","source":["#### It is important to note that **runs are always created programmatically**\n","\n","#### In other words, the Graphical User Interface (GUI) lets you browse experiments and their runs, but it does not have a “New Run” button.\n","\n","#### A run is essentially the result of executing some training/analysis code, and it gets logged automatically when you assign it using mlflow.start_run(...). <br><br>\n","\n","#### MLflow is an open-source Machine Learning Ops framework originally created by Databricks, and it is widely used across many platforms.\n","#### MLOps (Machine Learning Operations) is a set of practices, tools, and processes that help teams build, train, deploy, monitor, and maintain machine learning models reliably and at scale.\n","\n","#### Documentation about MLflow can be found here: https://mlflow.org/docs/latest/"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b82fcb1b-df20-4149-9ba7-5645e57f34c4"},{"cell_type":"markdown","source":["#### **Import ML Flow and set your experiment**\n","##### We are going to import ML Flow and relevant packages and define our experiment name"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e6cc6603-d803-44fd-a7ee-6e9bf25228fb"},{"cell_type":"code","source":["#Import MLflow and key packages we will need\n","import mlflow\n","import mlflow.sklearn\n","from mlflow.models import infer_signature\n","import pandas as pd\n","import statsmodels.api as sm\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Point to your existing experiment\n","mlflow.set_experiment(\"Experiment1\")\n"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d6ee72ee-0df8-404e-91d2-dfab59acd01d"},{"cell_type":"markdown","source":["##### Then we'll turn autologging off. If you keep autologging on, Fabric will store lots of different runs and information, much of which we might not need. We'll look at how to request exactly what you want. If you wish to keep autologging on you can explore this out of the session. It would create a generically named run alongside the one we create."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"eee2a471-29ce-43c7-810e-a7d68cc835ff"},{"cell_type":"code","source":["# Disable any autologgers that might auto-start a run: \n","# This ensures we don't get randomly generated runs, just the one we define\n","try:\n","    mlflow.autolog(disable=True)\n","except Exception:\n","    pass\n","for _autolog in (\"sklearn\", \"spark\", \"pyspark.ml\", \"xgboost\", \"lightgbm\", \"tensorflow\", \"pytorch\"):\n","    try:\n","        getattr(mlflow, _autolog).autolog(disable=True)\n","    except Exception:\n","        pass"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cfbcde4d-50b3-4593-9c13-b5ff3d72d05d"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run both code blocks above to import ML Flow, point to your experiment (change the name as required) and turn autologging off"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"e80b2f82-b612-4392-b756-ccec613f877f"},{"cell_type":"markdown","source":["### 2. Create linear regression"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8d624104-fd97-41ff-8b58-e58f4c8a49d6"},{"cell_type":"markdown","source":["#### &nbsp;&nbsp;&nbsp; **a. Create linear regression model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ffd68ba0-b779-41d8-a459-602bc8e5f218"},{"cell_type":"markdown","source":["#### **Create Linear Regression Model (2 variables)**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5fb15d6-f1bd-424c-9d3d-0aa937e82a56"},{"cell_type":"markdown","source":["\n","#### **The key steps here are:**\n","\n","#### 1. Define the dependent variable and independent variables for our Linear Regression\n","#### 2. Create the model, storing key information from that model into a run (review the code below for more details). <br><br>\n","#### In this section we are using **two** types of Linear Regressions available to us. One is **OLS** from **Statsmodels** and the other is **Linear Regression** from **sklearn** (also known as scikit-learn). This is because **OLS** is better for the **Model Summary** it produces but isn't integrated into **MLFlow** like **sklearn** so it won't work when trying to make predictions later in the process. The mathematical process is exactly the same for both types so we will get the same results whilst benefiting from both packages. <br><br>\n","\n","#### Step 1: Define the dependent and independent variables\n","\n","##### **Key points to be aware of:**\n","##### 1. Make sure the dataset is using the correct one - here we are using **Retail_Sales_pd_clean**\n","##### 2. Ensure you have defined the IVs and DV that you want\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c3ebb2b6-3c06-4a1c-8e10-b644e02cbce5"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 1. Define IVs and DV: Ensure dataframe is correct\n","# ------------------------------------------------\n","feature_cols = [\"ad_spend\", \"foot_traffic\"]\n","\n","X = Retail_Sales_pd_clean[feature_cols]\n","y = Retail_Sales_pd_clean[\"monthly_sales\"]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"52e637e1-40be-452d-b77e-0cfcb067ec9d"},{"cell_type":"markdown","source":["#### Step 2: Create Linear Regression model and store key information into a run\n","\n","##### **Key points to be aware of:**\n","##### 1. Define the run name as required: here we are calling it **linear_regression_Monthly_Sales**\n","##### 2. See if you want to change any parameters and metrics from MLflow that you wish to store for that run. In my experience, it is easier to use GenAI to identify the correct naming for these elements rather than the MLflow documentation"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"5abc2ed7-93f4-49e3-9725-fa3d6f71adbb"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 2. Train OLS (for summary) + sklearn (for logged model)\n","# ------------------------------------------------\n","\n","# ------------------------------------------------\n","# User Settings: Define run name\n","# ------------------------------------------------\n","with mlflow.start_run(run_name=\"linear_regression_Monthly_Sales\"):\n","\n","# -------- Save OLS model (statsmodels) for rich summary to the run--------\n","    X_sm = sm.add_constant(X)  # add intercept term\n","    ols_model = sm.OLS(y, X_sm).fit()\n","    ols_summary_text = ols_model.summary().as_text()\n","\n","    # Log OLS summary as a text artifact in this run\n","    mlflow.log_text(ols_summary_text, artifact_file=\"ols_model_summary.txt\")\n","\n","\n","# --- Log OLS coefficients, p-values, F-stat, Prob(F-stat) ---\n","    # Coefficients (including intercept/const)\n","    for name, value in ols_model.params.items():\n","        mlflow.log_metric(f\"ols_coef_{name}\", float(value))\n","\n","    # P-values for each coefficient\n","    for name, value in ols_model.pvalues.items():\n","        mlflow.log_metric(f\"ols_pvalue_{name}\", float(value))\n","\n","    # F-statistic and its p-value\n","    if ols_model.fvalue is not None:\n","        mlflow.log_metric(\"ols_f_statistic\", float(ols_model.fvalue))\n","    if ols_model.f_pvalue is not None:\n","        mlflow.log_metric(\"ols_prob_f_statistic\", float(ols_model.f_pvalue))\n","\n","# -------- sklearn LinearRegression for deployment/logging --------\n","    sk_model = LinearRegression()\n","    sk_model.fit(X, y)\n","\n","    # Predictions from sklearn model (for metrics + signature)\n","    y_pred = sk_model.predict(X)\n","\n","    mse = mean_squared_error(y, y_pred)\n","    r2 = r2_score(y, y_pred)\n","\n","    # Log params + metrics related to the sklearn model\n","    mlflow.log_param(\"model_type\", \"LinearRegression (sklearn)\")\n","    mlflow.log_param(\"features\", feature_cols)\n","    mlflow.log_metric(\"mse_train_full\", mse)\n","    mlflow.log_metric(\"r2_train_full\", r2)\n","\n","    # Log feature list as artifact\n","    mlflow.log_dict({\"feature_cols\": feature_cols}, artifact_file=\"feature_columns.json\")\n","\n","    # Create DataFrame for predictions with a named column (for output schema)\n","    y_pred_df = pd.DataFrame({\"prediction\": y_pred})\n","\n","    # Create signature with named output column \"prediction\"\n","    signature = infer_signature(X, y_pred_df)\n","\n","    # Log the sklearn model with signature + input example\n","    mlflow.sklearn.log_model(\n","        sk_model=sk_model,\n","        artifact_path=\"model\",\n","        signature=signature,\n","        input_example=X.head(5)\n","    )\n","\n","# ------------------------------------------------\n","# Print the OLS summary in the notebook\n","# ------------------------------------------------\n","print(ols_summary_text)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9ff8e428-cfa6-4902-a3ec-ec74ed6edade"},{"cell_type":"markdown","source":["#### **Observe the key statistics within the Model Summary**\n","#### View the adjusted r-squared, coefficients and p-values, F-statistic and Prob (F-statistic)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b633bf84-1906-4b15-b543-d5267629c111"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run two code cells above to define the variables and then create linear regression and save key information to the run"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5db664b-9fdf-4db6-adad-3be4af4d6eb0"},{"cell_type":"markdown","source":["#### **b. View the First Run**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c3f8124c-133c-438a-993b-2fc4ec9b6f9e"},{"cell_type":"markdown","source":["#### We are now ready to view the run. We will do this via the Graphical User Interface in Microsoft Fabric. <br> <br>\n","\n","#### The quickest way is to click on the Run Name that is generated after the run OR\n","#### Open the Experiment (**Experiment1**) from the **workspace** <br> <br>\n","#### Which ever way you choose, you can then view the runs on the left-hand side  <br> <br>\n","\n","#### **Key points:**\n","#### 1. If you click on it, you can see a txt file has been generated – click on this to view the model_summary that has been saved.\n","#### 2. In the main pane, we have details about the run, like the name, the date it was run, the experiment it has been assigned to and Run details: metrics like r2, and f_statistic, run parameters like coefficients, features and no. of rows. \n","#### 3. It also shows you the input and output schema which are the IVs and DV. **It is essential that these are showing ready for when you decide on the final model.** <br> <br>\n","#### This gives you a sense of how you can start building up information about that specific iteration of the linear regression model.\n","\n","\n","\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"02a33a5b-88cf-492b-92ac-c466e84becec"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### View the Run using the Graphical User Interface"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d5584d57-f92b-4e85-9293-7081bbbd9ad8"},{"cell_type":"markdown","source":["#### **c. Create a 2nd run and view it**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"e4956c4e-460d-46cd-b333-a04bcde0218e"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the **Linear Regression Code** again and **view** this 2nd run"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4eac8979-1ff4-4b6b-bf88-7c604215cc0b"},{"cell_type":"markdown","source":["#### Observe that if we run the code above twice, we get 2 runs named the same. <br><br>\n","\n","#### This is because every time you execute mlflow.start_run(...) you create a new run, even if you reuse the same run_name. run_name is just a label; it’s not unique. This is useful for comparing multiple attempts of the same experiment.\n","\n","#### If you’d prefer clearer separation it's fine to rename your runs. One approach is to automatically add the date/time at the end of the run name\n","\n","##### **Various options are available to automatically add labels to the name like add the date/time at the end of the run name but are outside the scope of this session. GenAI tools are a great way of exploring the options available to you**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"25f56b1f-3bcd-4f49-b5bc-db75f44fed73"},{"cell_type":"markdown","source":["### 3. Improve the Linear Regression"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d285df0b-515f-4012-a5e6-6ad62f479525"},{"cell_type":"markdown","source":["#### We are now going to make some adjustments to the linear regression model to see if we can improve it by adjusting the variables.\n","#### We'll then see how we can compare different runs to see which one is optimal for selection as the final model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ae9c91fe-faa8-4d9a-b608-fe85f27f216a"},{"cell_type":"markdown","source":["#### **a. Try and improve the model by adding avg_Price**\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1e2b8d25-eec8-4fa4-b344-07832ffc4b8c"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 1. Define IVs and DV: Ensure dataframe is correct\n","# ------------------------------------------------\n","feature_cols = [\"ad_spend\", \"foot_traffic\", \"avg_price\"]\n","\n","X = Retail_Sales_pd_clean[feature_cols]\n","y = Retail_Sales_pd_clean[\"monthly_sales\"]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"64d809d8-f524-4203-b1c5-c3d3da0be6de"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 2. Train OLS (for summary) + sklearn (for logged model)\n","# ------------------------------------------------\n","\n","# ------------------------------------------------\n","# User Settings: Define run name\n","# ------------------------------------------------\n","with mlflow.start_run(run_name=\"linear_regression_Monthly_Sales\"):\n","\n","# -------- Save OLS model (statsmodels) for rich summary to the run--------\n","    X_sm = sm.add_constant(X)  # add intercept term\n","    ols_model = sm.OLS(y, X_sm).fit()\n","    ols_summary_text = ols_model.summary().as_text()\n","\n","    # Log OLS summary as a text artifact in this run\n","    mlflow.log_text(ols_summary_text, artifact_file=\"ols_model_summary.txt\")\n","\n","\n","# --- Log OLS coefficients, p-values, F-stat, Prob(F-stat) ---\n","    # Coefficients (including intercept/const)\n","    for name, value in ols_model.params.items():\n","        mlflow.log_metric(f\"ols_coef_{name}\", float(value))\n","\n","    # P-values for each coefficient\n","    for name, value in ols_model.pvalues.items():\n","        mlflow.log_metric(f\"ols_pvalue_{name}\", float(value))\n","\n","    # F-statistic and its p-value\n","    if ols_model.fvalue is not None:\n","        mlflow.log_metric(\"ols_f_statistic\", float(ols_model.fvalue))\n","    if ols_model.f_pvalue is not None:\n","        mlflow.log_metric(\"ols_prob_f_statistic\", float(ols_model.f_pvalue))\n","\n","# -------- sklearn LinearRegression for deployment/logging --------\n","    sk_model = LinearRegression()\n","    sk_model.fit(X, y)\n","\n","    # Predictions from sklearn model (for metrics + signature)\n","    y_pred = sk_model.predict(X)\n","\n","    mse = mean_squared_error(y, y_pred)\n","    r2 = r2_score(y, y_pred)\n","\n","    # Log params + metrics related to the sklearn model\n","    mlflow.log_param(\"model_type\", \"LinearRegression (sklearn)\")\n","    mlflow.log_param(\"features\", feature_cols)\n","    mlflow.log_metric(\"mse_train_full\", mse)\n","    mlflow.log_metric(\"r2_train_full\", r2)\n","\n","    # Log feature list as artifact\n","    mlflow.log_dict({\"feature_cols\": feature_cols}, artifact_file=\"feature_columns.json\")\n","\n","    # Create DataFrame for predictions with a named column (for output schema)\n","    y_pred_df = pd.DataFrame({\"prediction\": y_pred})\n","\n","    # Create signature with named output column \"prediction\"\n","    signature = infer_signature(X, y_pred_df)\n","\n","    # Log the sklearn model with signature + input example\n","    mlflow.sklearn.log_model(\n","        sk_model=sk_model,\n","        artifact_path=\"model\",\n","        signature=signature,\n","        input_example=X.head(5)\n","    )\n","\n","# ------------------------------------------------\n","# Print the OLS summary in the notebook\n","# ------------------------------------------------\n","print(ols_summary_text)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"dc0fbe16-0b9b-48b0-986d-a23903e75e97"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the code above with the 3 independent variables and view the new run in the experiment"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fa2f27ae-c9ab-4d9f-80dd-7a00735acdb0"},{"cell_type":"markdown","source":["#### **b. Compare the runs in the Experiment interface and compare using the different functionality available**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9ec0ecf8-66a2-48a1-aa16-c56f4ad6e1ec"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Go to the Experiment **Experiment1** and compare the different elements of the run to choose which will be the final model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a10da4c2-405c-494d-858a-e6fde8722b28"},{"cell_type":"markdown","source":["### 4. Save a run as an ML Model using the Graphical User Interface <br><br>\n","\n","#### Choose a run - click on the ellipsis and select **Open**. Save the Run as an ML Model and **Create a new ML Model**. **It is important to choose Folder: Model** and then name it as required (eg **MonthlySales_LR**)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0536cd22-2bb7-4a73-b0ee-dcee47f220d3"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### In the Experiment, choose the run you want to make the final model. Observe that this item is now in the workspace as an **ML Model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ce37fa9c-8653-4bc3-bb1c-1f3f2dbc8130"},{"cell_type":"markdown","source":["## **Code Based Only** <br><br>\n","\n","##### Our aim in this section is to:\n","##### 1.\tCreate an Experiment and get set up with MLflow\n","##### 2.\tCreate our linear regression model\n","##### 3.\tImprove the regression model by adjusting the variables and we’ll the view the runs that are created within the experiment we’ve set up. This will allow us to compare those different runs.\n","##### 4.    Save the run as an ML model <br><br>\n","##### **_This section is a code only approach_**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"106905b6-a662-4212-a80f-7848512d039b"},{"cell_type":"markdown","source":["### 1. Create an Experiment and MLflow set up"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"87eecace-494d-43f8-b08f-e1044360ab67"},{"cell_type":"markdown","source":["#### **Import ML Flow and set your experiment**\n","##### We are going to import ML Flow and relevant packages and define our experiment name\n","##### Notice that we are running the same code as in the GUI section for the experiment. If the experiment doesn't already exist, **mlflow.set_experiment** will create it for you."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c5725d0e-d582-4ee3-8c68-9675822d53d3"},{"cell_type":"code","source":["#Import MLflow and key packages we will need\n","import mlflow\n","import mlflow.sklearn\n","from mlflow.models import infer_signature\n","import pandas as pd\n","import statsmodels.api as sm\n","\n","from sklearn.linear_model import LinearRegression\n","from sklearn.metrics import mean_squared_error, r2_score\n","\n","# Point to your existing experiment\n","mlflow.set_experiment(\"Experiment2\") #CHANGE THE EXPERIMENT NAME HERE#"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9dfb03d0-de02-4002-9437-59204b27ad6a"},{"cell_type":"markdown","source":["##### Then we'll turn autologging off. If you keep autologging on, Fabric will store lots of different runs and information, much of which we might not need. We'll look at how to request exactly what you want. If you wish to keep autologging on you can explore this out of the session. It would create a generically named run alongside the one we create."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ffddbbaf-2079-4541-a00e-a3205719b5f2"},{"cell_type":"code","source":["# Disable any autologgers that might auto-start a run: \n","# This ensures we don't get randomly generated runs, just the one we define\n","try:\n","    mlflow.autolog(disable=True)\n","except Exception:\n","    pass\n","for _autolog in (\"sklearn\", \"spark\", \"pyspark.ml\", \"xgboost\", \"lightgbm\", \"tensorflow\", \"pytorch\"):\n","    try:\n","        getattr(mlflow, _autolog).autolog(disable=True)\n","    except Exception:\n","        pass"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a5ba0c22-0211-42e7-b0ab-482360823084"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the 2 code cells above to import the required packages, create an experiment called **Experiment2** and turn autologging off"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7c9c311f-deca-4a50-ac55-2cb5cc21bec9"},{"cell_type":"markdown","source":["### 2. Create linear regression"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"6acbf92e-11c8-41c2-a49a-76025cdf30c8"},{"cell_type":"markdown","source":["#### &nbsp;&nbsp;&nbsp; **a. Create linear regression model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bf2ac41f-6380-4487-95d8-746ffd444b1a"},{"cell_type":"markdown","source":["#### These code cells are defining the DV and IVs and then created the linear regression. It is the same process as the GUI section. Please see that section for further details on this code."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d9ce96ef-66a2-43ed-a02c-ca054052b680"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 1. Define IVs and DV: Ensure dataframe is correct\n","# ------------------------------------------------\n","feature_cols = [\"ad_spend\", \"foot_traffic\"]\n","\n","X = Retail_Sales_pd_clean[feature_cols]\n","y = Retail_Sales_pd_clean[\"monthly_sales\"]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"27fad477-25f3-402e-a8cd-665e6608d4e1"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 2. Train OLS (for summary) + sklearn (for logged model)\n","# ------------------------------------------------\n","\n","# ------------------------------------------------\n","# User Settings: Define run name\n","# ------------------------------------------------\n","with mlflow.start_run(run_name=\"linear_regression_Monthly_Sales\"):\n","\n","# -------- Save OLS model (statsmodels) for rich summary to the run--------\n","    X_sm = sm.add_constant(X)  # add intercept term\n","    ols_model = sm.OLS(y, X_sm).fit()\n","    ols_summary_text = ols_model.summary().as_text()\n","\n","    # Log OLS summary as a text artifact in this run\n","    mlflow.log_text(ols_summary_text, artifact_file=\"ols_model_summary.txt\")\n","\n","\n","# --- Log OLS coefficients, p-values, F-stat, Prob(F-stat) ---\n","    # Coefficients (including intercept/const)\n","    for name, value in ols_model.params.items():\n","        mlflow.log_metric(f\"ols_coef_{name}\", float(value))\n","\n","    # P-values for each coefficient\n","    for name, value in ols_model.pvalues.items():\n","        mlflow.log_metric(f\"ols_pvalue_{name}\", float(value))\n","\n","    # F-statistic and its p-value\n","    if ols_model.fvalue is not None:\n","        mlflow.log_metric(\"ols_f_statistic\", float(ols_model.fvalue))\n","    if ols_model.f_pvalue is not None:\n","        mlflow.log_metric(\"ols_prob_f_statistic\", float(ols_model.f_pvalue))\n","\n","# -------- sklearn LinearRegression for deployment/logging --------\n","    sk_model = LinearRegression()\n","    sk_model.fit(X, y)\n","\n","    # Predictions from sklearn model (for metrics + signature)\n","    y_pred = sk_model.predict(X)\n","\n","    mse = mean_squared_error(y, y_pred)\n","    r2 = r2_score(y, y_pred)\n","\n","    # Log params + metrics related to the sklearn model\n","    mlflow.log_param(\"model_type\", \"LinearRegression (sklearn)\")\n","    mlflow.log_param(\"features\", feature_cols)\n","    mlflow.log_metric(\"mse_train_full\", mse)\n","    mlflow.log_metric(\"r2_train_full\", r2)\n","\n","    # Log feature list as artifact\n","    mlflow.log_dict({\"feature_cols\": feature_cols}, artifact_file=\"feature_columns.json\")\n","\n","    # Create DataFrame for predictions with a named column (for output schema)\n","    y_pred_df = pd.DataFrame({\"prediction\": y_pred})\n","\n","    # Create signature with named output column \"prediction\"\n","    signature = infer_signature(X, y_pred_df)\n","\n","    # Log the sklearn model with signature + input example\n","    mlflow.sklearn.log_model(\n","        sk_model=sk_model,\n","        artifact_path=\"model\",\n","        signature=signature,\n","        input_example=X.head(5)\n","    )\n","\n","# ------------------------------------------------\n","# Print the OLS summary in the notebook\n","# ------------------------------------------------\n","print(ols_summary_text)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fcec4155-3496-4711-aea2-00724f11b212"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run two code cells above to define the variables and then create linear regression and save key information to the run"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a18a0d7f-8fec-4d63-af32-c82b05f16c5d"},{"cell_type":"markdown","source":["#### **b. View the First Run**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5d86d6d2-27ea-48ff-8bc4-6cab7389b11c"},{"cell_type":"markdown","source":["#### We are now ready to view the run. We will do this using **code**. <br> <br>"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"c9683742-2635-4310-81b5-1d01cd10e270"},{"cell_type":"code","source":["# --------------------------------------------------------\n","# USER SETTINGS\n","# --------------------------------------------------------\n","\n","experiment_name = \"Experiment2\" #UPDATE EXPERIMENT NAME AS REQUIRED*\n","\n","##############################################################################\n","##############################################################################\n","\n","# Get experiment object (will throw an exception if not found, so it's a nice sanity check)\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","experiment_id = experiment.experiment_id\n","print(f\"Experiment id for {experiment_name}: {experiment_id}\")\n","\n","# Pull all runs for this experiment\n","runs_df = mlflow.search_runs(\n","    experiment_ids=[experiment_id],\n","    order_by=[\"metrics.r2_train_full DESC\"]   # sort by your metric of interest\n",")\n","\n","\n","# ----------------------------------------------\n","# 1. Extract all coefficient & p-value metric names\n","# ----------------------------------------------\n","coef_cols = [c for c in runs_df.columns if c.startswith(\"metrics.ols_coef_\")]\n","pval_cols = [c for c in runs_df.columns if c.startswith(\"metrics.ols_pvalue_\")]\n","\n","# ----------------------------------------------\n","# 2. Build base cols to show\n","# ----------------------------------------------\n","base_cols = [\n","    \"run_id\",\n","    \"status\",\n","    \"start_time\",\n","    \"metrics.r2_train_full\",\n","    \"params.model_type\",\n","]\n","\n","# ----------------------------------------------\n","# 3. Add input schema (signature) as a column\n","# ----------------------------------------------\n","def get_signature(run_id):\n","    try:\n","        model_uri = f\"runs:/{run_id}/model\"\n","        info = mlflow.models.get_model_info(model_uri)\n","        return str(info.signature)\n","    except:\n","        return None\n","\n","runs_df[\"input_schema\"] = runs_df[\"run_id\"].apply(get_signature)\n","\n","# ----------------------------------------------\n","# 4. Build final columns list\n","# ----------------------------------------------\n","cols_to_show = base_cols + coef_cols + pval_cols + [\"input_schema\"]\n","\n","# Show results\n","runs_df[cols_to_show]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"78313537-e5dd-4c3c-81b9-d9b6ce246539"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the cell above to view the run"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"71fa8f16-5556-4186-978d-d3a50c480735"},{"cell_type":"markdown","source":["### 3. Improve the Linear Regression"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"b6150aef-ff21-4b40-a01e-c467dc4a4782"},{"cell_type":"markdown","source":["#### We are now going to make some adjustments to the linear regression model to see if we can improve it by adjusting the variables.\n","#### We'll then see how we can compare different runs to see which one is optimal for selection as the final model"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ffb9501e-2e50-454c-a21b-19ecc0e13357"},{"cell_type":"markdown","source":["#### **a. Try and improve the model by adding avg_Price**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"f49635a7-ddab-498f-b958-62f0893aeb87"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 1. Define IVs and DV: Ensure dataframe is correct\n","# ------------------------------------------------\n","feature_cols = [\"ad_spend\", \"foot_traffic\", \"avg_price\"]\n","\n","X = Retail_Sales_pd_clean[feature_cols]\n","y = Retail_Sales_pd_clean[\"monthly_sales\"]"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"1b9fc5e9-0bd0-4c23-aa6d-e579c6f24ea3"},{"cell_type":"code","source":["# ------------------------------------------------\n","# 2. Train OLS (for summary) + sklearn (for logged model)\n","# ------------------------------------------------\n","\n","# ------------------------------------------------\n","# User Settings: Define run name\n","# ------------------------------------------------\n","with mlflow.start_run(run_name=\"linear_regression_Monthly_Sales\"):\n","\n","# -------- Save OLS model (statsmodels) for rich summary to the run--------\n","    X_sm = sm.add_constant(X)  # add intercept term\n","    ols_model = sm.OLS(y, X_sm).fit()\n","    ols_summary_text = ols_model.summary().as_text()\n","\n","    # Log OLS summary as a text artifact in this run\n","    mlflow.log_text(ols_summary_text, artifact_file=\"ols_model_summary.txt\")\n","\n","\n","# --- Log OLS coefficients, p-values, F-stat, Prob(F-stat) ---\n","    # Coefficients (including intercept/const)\n","    for name, value in ols_model.params.items():\n","        mlflow.log_metric(f\"ols_coef_{name}\", float(value))\n","\n","    # P-values for each coefficient\n","    for name, value in ols_model.pvalues.items():\n","        mlflow.log_metric(f\"ols_pvalue_{name}\", float(value))\n","\n","    # F-statistic and its p-value\n","    if ols_model.fvalue is not None:\n","        mlflow.log_metric(\"ols_f_statistic\", float(ols_model.fvalue))\n","    if ols_model.f_pvalue is not None:\n","        mlflow.log_metric(\"ols_prob_f_statistic\", float(ols_model.f_pvalue))\n","\n","# -------- sklearn LinearRegression for deployment/logging --------\n","    sk_model = LinearRegression()\n","    sk_model.fit(X, y)\n","\n","    # Predictions from sklearn model (for metrics + signature)\n","    y_pred = sk_model.predict(X)\n","\n","    mse = mean_squared_error(y, y_pred)\n","    r2 = r2_score(y, y_pred)\n","\n","    # Log params + metrics related to the sklearn model\n","    mlflow.log_param(\"model_type\", \"LinearRegression (sklearn)\")\n","    mlflow.log_param(\"features\", feature_cols)\n","    mlflow.log_metric(\"mse_train_full\", mse)\n","    mlflow.log_metric(\"r2_train_full\", r2)\n","\n","    # Log feature list as artifact\n","    mlflow.log_dict({\"feature_cols\": feature_cols}, artifact_file=\"feature_columns.json\")\n","\n","    # Create DataFrame for predictions with a named column (for output schema)\n","    y_pred_df = pd.DataFrame({\"prediction\": y_pred})\n","\n","    # Create signature with named output column \"prediction\"\n","    signature = infer_signature(X, y_pred_df)\n","\n","    # Log the sklearn model with signature + input example\n","    mlflow.sklearn.log_model(\n","        sk_model=sk_model,\n","        artifact_path=\"model\",\n","        signature=signature,\n","        input_example=X.head(5)\n","    )\n","\n","# ------------------------------------------------\n","# Print the OLS summary in the notebook\n","# ------------------------------------------------\n","print(ols_summary_text)"],"outputs":[],"execution_count":null,"metadata":{"jupyter":{"source_hidden":false,"outputs_hidden":false},"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"6f5231f3-714a-49b1-8cdc-9f077f125632"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the code above with the 3 independent variables"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"8d8669fc-0628-4406-8d55-00fc1c9644ef"},{"cell_type":"markdown","source":["#### **b. Compare the runs using code and filter as required**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9d5d229f-96b5-48d2-944e-d54de1fd9af1"},{"cell_type":"code","source":["import mlflow\n","import pandas as pd\n","\n","# --------------------------------------------------------\n","# USER SETTINGS\n","# --------------------------------------------------------\n","experiment_name = \"Experiment2\"  # UPDATE EXPERIMENT NAME AS REQUIRED\n","\n","filter_string = \"metrics.r2_train_full > 0.6\"  # SET ANY FILTERS YOU WANT\n","#filter_string = \"metrics.r2_train_full > 0.4 AND metrics.ols_pvalue_const <0.05 \"  # ALTERNATIVE SYNTAX FOR MULITPLE FILTERS\n","#filter_string = None  # uncomment to disable filtering\n","\n","# --------------------------------------------------------\n","# LOAD EXPERIMENT\n","# --------------------------------------------------------\n","experiment = mlflow.get_experiment_by_name(experiment_name)\n","experiment_id = experiment.experiment_id\n","print(f\"Experiment id for {experiment_name}: {experiment_id}\")\n","\n","# --------------------------------------------------------\n","# QUERY RUNS (WITH OPTIONAL FILTER)\n","# --------------------------------------------------------\n","search_args = dict(\n","    experiment_ids=[experiment_id],\n","    order_by=[\"metrics.r2_train_full DESC\"],\n",")\n","\n","if filter_string:\n","    search_args[\"filter_string\"] = filter_string\n","\n","runs_df = mlflow.search_runs(**search_args)\n","\n","# --------------------------------------------------------\n","# HANDLE CASE: NO RUNS MATCH FILTER\n","# --------------------------------------------------------\n","if runs_df.empty:\n","    print(\n","        f\"No runs found for experiment '{experiment_name}' \"\n","        f\"with filter: {filter_string!r}\"\n","    )\n","    # Optional: show all runs without filter so you can see what's available\n","    # all_runs_df = mlflow.search_runs(experiment_ids=[experiment_id])\n","    # display(all_runs_df)\n","else:\n","    print(f\"Runs returned: {len(runs_df)}\")\n","\n","    # ----------------------------------------------\n","    # 1. Extract all coefficient & p-value metric names\n","    # ----------------------------------------------\n","    coef_cols = [c for c in runs_df.columns if c.startswith(\"metrics.ols_coef_\")]\n","    pval_cols = [c for c in runs_df.columns if c.startswith(\"metrics.ols_pvalue_\")]\n","\n","    # ----------------------------------------------\n","    # 2. Build base cols to show (only those that actually exist)\n","    # ----------------------------------------------\n","    candidate_base_cols = [\n","        \"run_id\",\n","        \"status\",\n","        \"start_time\",\n","        \"metrics.r2_train_full\",\n","        \"params.model_type\",\n","    ]\n","    base_cols = [c for c in candidate_base_cols if c in runs_df.columns]\n","\n","    # ----------------------------------------------\n","    # 3. Add input schema (signature) as a column\n","    # ----------------------------------------------\n","    def get_signature(run_id):\n","        try:\n","            model_uri = f\"runs:/{run_id}/model\"\n","            info = mlflow.models.get_model_info(model_uri)\n","            return str(info.signature)\n","        except Exception:\n","            return None\n","\n","    runs_df[\"input_schema\"] = runs_df[\"run_id\"].apply(get_signature)\n","\n","    # ----------------------------------------------\n","    # 4. Build final columns list\n","    # ----------------------------------------------\n","    cols_to_show = base_cols + coef_cols + pval_cols + [\"input_schema\"]\n","\n","    # Show results as a nice table\n","    display(runs_df[cols_to_show])\n","    "],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"3718a9f4-c250-4481-aa74-4ceeb4e34671"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### View the runs in the experiment using code and filter as required"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"0133765c-7351-43fa-a089-de4e76f8eb00"},{"cell_type":"markdown","source":["### 4. Save a run as an ML Model using code <br><br>\n","\n","#### **a. Choose a run you want to deploy as a model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a179a933-446e-416f-bbc1-04e61745fc71"},{"cell_type":"code","source":["import mlflow\n","\n","# ============================\n","# USER SETTINGS\n","# ============================\n","run_id = \"bc2763ff-78dd-43c1-b9c9-62da81babd72\"   # run to promote\n","MODEL_NAME = \"MonthlySales_LR_Experiment2\"        # MLflow registered model name\n","OUTPUT_COL = \"PredictedMonthlySales\"              # desired output column name\n","\n","# Version control:\n","# Choose ONE of these:\n","USE_NEXT_VERSION = True      # Set to either True or False: If True it will automatically use the next available model version. If false, you need to set the OVERRIDE_VERSION to a number\n","OVERRIDE_VERSION = None      # e.g. 5 → manually set model version; leave None to disable\n","\n","#############################################################\n","#############################################################\n","\n","# ============================================\n","# AUTOMATED MODEL REGISTRATION + TRANSFORMER\n","# This step turns the MLflow model into a Spark transformer so it can make predictions on your data in Fabric\n","# ============================================\n","import mlflow\n","import json\n","from mlflow.tracking import MlflowClient\n","from synapse.ml.predict import MLFlowTransformer\n","\n","client = MlflowClient()\n","\n","# ------------------------------------------------\n","# 1. Sanity check version settings\n","# ------------------------------------------------\n","if USE_NEXT_VERSION and OVERRIDE_VERSION is not None:\n","    raise ValueError(\n","        \"Please choose only one version strategy: \"\n","        \"either USE_NEXT_VERSION = True or set OVERRIDE_VERSION (and USE_NEXT_VERSION = False).\"\n","    )\n","\n","# ------------------------------------------------\n","# 2. Determine model URI for this run\n","# ------------------------------------------------\n","model_uri = f\"runs:/{run_id}/model\"\n","print(f\"Using model URI: {model_uri}\")\n","\n","# ------------------------------------------------\n","# 3. Automatically determine input columns\n","#    - First try feature_columns.json (if logged)\n","#    - Fallback: infer from MLflow model signature\n","# ------------------------------------------------\n","input_cols = None\n","\n","# 3a. Try feature_columns.json artifact\n","try:\n","    # Assumes training code logged: mlflow.log_dict({\"feature_cols\": feature_cols}, \"feature_columns.json\")\n","    local_path = client.download_artifacts(run_id, \"feature_columns.json\")\n","    with open(local_path, \"r\") as f:\n","        feature_info = json.load(f)\n","    input_cols = feature_info.get(\"feature_cols\")\n","    if input_cols:\n","        print(f\"Loaded input columns from feature_columns.json: {input_cols}\")\n","except Exception as e:\n","    print(\"Could not load feature_columns.json; will try to infer from model signature.\")\n","\n","# 3b. Fallback: infer from model signature\n","if not input_cols:\n","    try:\n","        model_info = mlflow.models.get_model_info(model_uri)\n","        sig = model_info.signature\n","        if sig and sig.inputs:\n","            input_cols = [field.name for field in sig.inputs.inputs]\n","            print(f\"Inferred input columns from signature: {input_cols}\")\n","    except Exception as e:\n","        print(\"Could not infer input columns from MLflow model signature.\")\n","\n","if not input_cols:\n","    raise ValueError(\n","        \"Unable to determine input columns from either feature_columns.json or model signature. \"\n","        \"Please check that one of these was logged for this run.\"\n","    )\n","\n","# ------------------------------------------------\n","# 4. Decide which model version to use\n","#    - Either register as next version\n","#    - Or use an explicitly overridden version\n","# ------------------------------------------------\n","if OVERRIDE_VERSION is not None:\n","    # Use an existing, manually specified version (no new registration)\n","    model_version = int(OVERRIDE_VERSION)\n","    print(f\"Using manually overridden model version: {model_version}\")\n","\n","elif USE_NEXT_VERSION:\n","    # Register the run’s model -> MLflow auto-assigns the next version number\n","    result = mlflow.register_model(\n","        model_uri=model_uri,\n","        name=MODEL_NAME\n","    )\n","    model_version = int(result.version)\n","    print(f\"Registered model '{MODEL_NAME}' as new version: {model_version}\")\n","\n","else:\n","    raise ValueError(\n","        \"No model version strategy selected. \"\n","        \"Set USE_NEXT_VERSION = True or specify OVERRIDE_VERSION.\"\n","    )\n","\n","# ------------------------------------------------\n","# 5. Build the MLFlowTransformer\n","#    (Builds a Spark transformer that uses this MLflow model\n","#     to generate predictions on Spark DataFrames.)\n","# ------------------------------------------------\n","mlflow_transformer = MLFlowTransformer(\n","    inputCols=input_cols,\n","    outputCol=OUTPUT_COL,\n","    modelName=MODEL_NAME,\n","    modelVersion=model_version\n",")\n","\n","print(\"\\nMLFlowTransformer is ready to use:\")\n","print(f\"  modelName    = {MODEL_NAME}\")\n","print(f\"  modelVersion = {model_version}\")\n","print(f\"  inputCols    = {input_cols}\")\n","print(f\"  outputCol    = {OUTPUT_COL}\")\n","\n","# Example usage (uncomment when you have a Spark DataFrame `df` with the required inputCols):\n","# scored_df = mlflow_transformer.transform(df)\n","# display(scored_df)\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9d9d5a62-e88e-43aa-ae16-c68fc62e4a1b"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### In the Experiment, choose the run you want to make the final model. Observe that this item is now in the workspace as an **ML Model**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"d8efc7c3-f2b8-43bb-ba74-b45e6e1937d4"},{"cell_type":"markdown","source":["#### **b. View list of models in the model registry**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4b196fc4-d59e-42f7-b42d-189fe6779e9b"},{"cell_type":"code","source":["# ============================================\n","# USER SETTINGS\n","# ============================================\n","# Set to None to show ALL models in the registry\n","# Or set to a specific model name, e.g. \"MonthlySales_LR_Experiment2\"\n","\n","FILTER_MODEL_NAME = None\n","#FILTER_MODEL_NAME = \"MonthlySales_LR_Experiment2\"\n","\n","\n","# ============================================\n","# LIST MODELS + ALL VERSIONS + PARAMS (ROBUST)\n","# ============================================\n","from mlflow.tracking import MlflowClient\n","import pandas as pd\n","\n","client = MlflowClient()\n","rows = []\n","\n","def add_model_versions_for_name(model_name: str):\n","    \"\"\"Collect rows for all versions of a given registered model name.\"\"\"\n","    global rows\n","    versions = client.search_model_versions(f\"name = '{model_name}'\")\n","    for v in versions:\n","        features = None\n","        model_type = None\n","\n","        # Try to fetch run params; if run is missing, keep going\n","        try:\n","            run = client.get_run(v.run_id)\n","            params = run.data.params\n","            features = params.get(\"features\")\n","            model_type = params.get(\"model_type\")\n","        except Exception as e:\n","            print(\n","                f\"Warning: could not fetch run {v.run_id} \"\n","                f\"for model '{v.name}' v{v.version}: {e}\"\n","            )\n","\n","        rows.append({\n","            \"model_name\": v.name,\n","            \"version\": int(v.version),\n","            \"stage\": v.current_stage,\n","            \"run_id\": v.run_id,\n","            \"features\": features,\n","            \"model_type\": model_type,\n","        })\n","\n","\n","if FILTER_MODEL_NAME:\n","    # ----------------------------------------\n","    # Case 1: Only show a specific model\n","    # ----------------------------------------\n","    model_name = FILTER_MODEL_NAME\n","    print(f\"Querying registry for model: {model_name!r}\")\n","\n","    try:\n","        _ = client.get_registered_model(model_name)  # sanity check\n","        add_model_versions_for_name(model_name)\n","    except Exception as e:\n","        print(f\"No registered model found with name {model_name!r}.\")\n","        print(\"Details:\", e)\n","\n","else:\n","    # ----------------------------------------\n","    # Case 2: Show ALL models in the registry\n","    # ----------------------------------------\n","    print(\"Querying registry for ALL models...\")\n","\n","    try:\n","        registered_models = client.search_registered_models()\n","\n","        if not registered_models:\n","            print(\"MLflow registry returned no registered models.\")\n","        else:\n","            for m in registered_models:\n","                add_model_versions_for_name(m.name)\n","    except Exception as e:\n","        print(\"Error while querying registered models root list:\")\n","        print(e)\n","\n","\n","# --------------------------------------------\n","# Build and display results table\n","# --------------------------------------------\n","if rows:\n","    df = pd.DataFrame(rows).sort_values([\"model_name\", \"version\"])\n","    unique_models = df[\"model_name\"].nunique()\n","    print(f\"\\nModels found in registry: {unique_models}\")\n","    display(df)\n","else:\n","    print(\"\\nNo models found in the MLflow Model Registry matching the filter criteria.\")\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"a5fdf316-b214-42ce-b206-7aaf2bc576df"},{"cell_type":"markdown","source":["## **Predict on New Data** \n","\n","##### Our aim in this section is to predict on new data\n","##### We are going to approach this in 2 ways\n","\n","##### 1. GUI Approach: using the wizard and the copy code option \n","##### 2. Code Based approach <br><br>\n","\n","##### NOTE: If we use the code that Microsoft Fabric generates (ie Option 1), it will create links unique to the tenant it was originally set up with. \n","##### As such the demo will showcase how to go through those options but repeatable code will be provided below for the \"code based approach\" of option 2.\n"],"metadata":{"nteract":{"transient":{"deleting":false}}},"id":"f4585dec-f5de-4685-8d0f-0f33a4f75566"},{"cell_type":"markdown","source":["#### **To set ourselves up to do this, we'll first source some data that we will save in our Lakehouse**\n","##### This data comes from GitHub and contains only variables, not the Monthly Sales.\n","##### We will use the model we have created to make predictions on the monthly sales based on those variables in this new dataset."],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"bba2af1c-d921-4700-a39f-db4bfd3b8292"},{"cell_type":"code","source":["#read the csv file from the github repo containing the new retail dataset called RetailSalesNewData.csv\n","import pandas as pd \n","\n","retail_new_data = pd.read_csv(\"https://github.com/EmpoweredAnalysts/FabricRetailSales/raw/refs/heads/main/RetailSalesNewData.csv\")\n","\n","# Load data to tables \n","# we need to use spark to write it to the tables section of the Lakehouse which is why we are converting it to a spark dataframe)\n","\n","# Convert pandas DataFrames to PySpark DataFrames\n","retail_new_data_spark = spark.createDataFrame(retail_new_data)\n","\n","# Write DataFrames to Delta table\n","retail_new_data_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"retail_new_data\")\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2e41e6f6-6eb5-4827-b896-bb43ab3df9b7"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the code in the cell above to read in the new dataset and save it to the Lakehouse\n","#### Refresh the Lakehouse to observe it has been added"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3cd5ce34-dd6e-4c47-b231-36219a82069f"},{"cell_type":"markdown","source":["#### **1. GUI approach using the wizard**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"cc15fbbe-50b9-4622-94aa-ff1e760da375"},{"cell_type":"code","source":[],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"5fb2b6a7-29fc-4f20-90c0-48886b16e219"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Go to the Model and choose **Apply this version** - first select **copy code to apply**. Observe that you would need to add the file path from the source location and the destination location.<br><br>\n","#### If you want help to do this, you can choose **Apply this version** - then select **Apply this model in Wizard** following the steps\n","#### Paste the code in the empty cell block below and it should run with your links (NOTE: If you paste it in, be careful of indents!!!)\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"585668f8-9274-484c-b90b-aea24923fb22"},{"cell_type":"markdown","source":["#### The code generated in this tenant looks like this:"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"a7efd9f7-3b2d-4423-aa27-4abdba30e1a3"},{"cell_type":"code","source":["import mlflow\n","from synapse.ml.predict import MLFlowTransformer\n","\n","df = spark.read.format(\"delta\").load(\n","    \"abfss://73e397d7-a3e5-4d23-af7d-b687d16d1c46@onelake.dfs.fabric.microsoft.com/b2a6adcd-fa7c-483c-98dc-9b2e4fbcaae0/Tables/retail_new_data\"\n",")\n","\n","model = MLFlowTransformer(\n","    inputCols=[\"ad_spend\",\"foot_traffic\",\"avg_price\"],\n","    outputCol=\"PredictedMonthlySales\",\n","    modelName=\"NewCheck\",\n","    modelVersion=3\n",")\n","df = model.transform(df)\n","\n","df.write.format('delta').mode(\"overwrite\").save(\n","    \"abfss://73e397d7-a3e5-4d23-af7d-b687d16d1c46@onelake.dfs.fabric.microsoft.com/b2a6adcd-fa7c-483c-98dc-9b2e4fbcaae0/Tables/new_retail_sales_predict\"\n",")"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"3956ba23-c147-4e9e-beb4-e2f40922ca43"},{"cell_type":"markdown","source":["#### Then drag across the new table from the Lakehouse into a cell (you might need to refresh the lakehouse)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"ffd0b795-0301-4d43-b494-ca8f61a841fa"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM DataScienceLakehouse.new_retail_sales_predict LIMIT 1000\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"38c54ea1-0aa2-4f6c-9bd3-3267fe59be1e"},{"cell_type":"markdown","source":[],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"9908b89b-2efe-4531-ac1d-9663d9edfe3b"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the 2 cells to predict on new data and then return the results, ensuring you use **YOUR** filepath names. Observe you now have a column called PredictedMonthlySales\n"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"2fbc7dcc-e2e7-40e0-8180-0b0c139198fd"},{"cell_type":"markdown","source":["#### **2. Code Based Approach**\n","\n","##### The code below is not tenant specific. Do make sure your Lakehouse is named **DataScienceLakehouse** and is attached in the Explorer pane on the left.\n","##### This code will generate a new table called **new_retail_sales_predict2**"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"32bf858e-5112-495a-8c53-13f34f5eff99"},{"cell_type":"code","source":["import mlflow\n","from synapse.ml.predict import MLFlowTransformer\n","\n","# ============================================\n","# USER SETTINGS\n","# ============================================\n","\n","# Read from the Lakehouse table: Make sure you have read the new data in and you are currently pointing to the correct Lakehouse in the File Explorer\n","df = spark.read.format(\"delta\").load(\"Tables/retail_new_data\")\n","\n","# Apply the model\n","model = MLFlowTransformer(\n","    inputCols=[\"ad_spend\", \"foot_traffic\", \"avg_price\"],\n","    outputCol=\"PredictedMonthlySales\",\n","    modelName=\"MonthlySales_LR_Experiment2\",\n","    modelVersion=1 #ENSURE THE MODEL VERSION IS THE CORRECT ONE***\n",")\n","# ============================================\n","\n","\n","df = model.transform(df)\n","df_pd = df.toPandas()\n","\n","# Write results back to a Delta table in the same Lakehouse\n","# Convert pandas DataFrames to PySpark DataFrames\n","df_pd_spark = spark.createDataFrame(df_pd)\n","\n","# ============================================\n","# USER SETTINGS\n","# ============================================\n","\n","# Write DataFrames to Delta table\n","df_pd_spark.write.format(\"delta\").mode(\"overwrite\").saveAsTable(\"new_retail_sales_predict2\")\n","\n","\n"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"7747f1f2-c0e8-43c4-a091-0a07ef045da4"},{"cell_type":"markdown","source":["#### Then drag across the new table from the Lakehouse into a cell (you might need to refresh the lakehouse)"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"4019262e-0c6b-45cd-97be-cfb2f9280136"},{"cell_type":"code","source":["df = spark.sql(\"SELECT * FROM DataScienceLakehouse.new_retail_sales_predict2 LIMIT 1000\")\n","display(df)"],"outputs":[],"execution_count":null,"metadata":{"microsoft":{"language":"python","language_group":"synapse_pyspark"},"collapsed":false},"id":"d56b32ca-75b4-4d5c-b932-8fcb9f7b6249"},{"cell_type":"markdown","source":["<div style=\"background-color: #e6f7ff; padding: 10px;\">\n","\n","#### **Activity:**\n","#### Run the 2 cells above to predict on new data and then return the results. Observe you now have a column called PredictedMonthlySales"],"metadata":{"nteract":{"transient":{"deleting":false}},"microsoft":{"language":"python","language_group":"synapse_pyspark"}},"id":"fe05c235-f598-473e-9ecc-9b0bca74bd11"}],"metadata":{"kernel_info":{"name":"synapse_pyspark"},"kernelspec":{"name":"synapse_pyspark","display_name":"synapse_pyspark"},"language_info":{"name":"python"},"microsoft":{"language":"python","language_group":"synapse_pyspark","ms_spell_check":{"ms_spell_check_language":"en"}},"nteract":{"version":"nteract-front-end@1.0.0"},"widgets":{},"synapse_widget":{"version":"0.1","state":{}},"spark_compute":{"compute_id":"/trident/default","session_options":{"conf":{"spark.synapse.nbs.session.timeout":"1200000"}}},"dependencies":{"lakehouse":{"known_lakehouses":[{"id":"f09b3702-6d77-47b6-a048-28214b22a2f5"}],"default_lakehouse":"f09b3702-6d77-47b6-a048-28214b22a2f5","default_lakehouse_name":"DataScienceLakehouse","default_lakehouse_workspace_id":"d8280304-38ea-436e-9dbb-c56239016605"}}},"nbformat":4,"nbformat_minor":5}